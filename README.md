## Orcasound Listening Experience

React prototype: [https://orcasound-dashboard.vercel.app/beta](https://orcasound-dashboard.vercel.app/beta)

UX case study: [https://www.adriandesigner.com/orcasound-listening-experience](https://www.adriandesigner.com/orcasound-listening-experience)

___

![After - candidate screens](https://github.com/user-attachments/assets/d8cf3850-785d-453e-bea3-cf2d97df6e6a)


### Design Goals
We set out to:
- Make past detections and user reports more discoverable.
- Provide a more interactive experience that helps users explore and analyze orca sounds.
- Start integrating AI detections to support learning and research.
- Build a foundation for richer conservation tools and community feedback.


The redesigned prototype introduces:

- A searchable, filterable list of historical recordings based on user reports and AI detections.
- Integrated spectrogram viewer and audio player for quick review and annotation.
- Previewable detection markers tied to audio segments for easier analysis.
- A responsive layout optimized for both desktop and mobile use.

---

### Built With

This prototype was built in React using:
- **Next.js** for app structure and routing
- **Material UI** for the component system
- **React Query** for data fetching and caching
- **Video.js** for advanced audio playback
- **GraphQL** to fetch detection and hydrophone metadata

This is an experimental prototype used for testing ideas and generating feedback. The design is open source and still evolving. Contributions and collaborations welcome!

